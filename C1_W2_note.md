+ Lab01 : (可选Lab，python，Numpy，矢量化)
  + Numpy中的数据创建例程通常有第一个参数，即对象的形状，这可以是一堆结果的单个值，也可以是指定结果形状的元组（n,m,……）
    + a = np.zeros(4);                
    + a = np.zeros((4,));             
    + 这两个的结果是相同的
  + 向量与向量之间的dot product (点乘)：
    + 向量与向量之间对应元素相乘 并加起来。最终返回一个结果（不是数组）
  + 矢量化与for循环的速度对比：
    + 矢量化的速度很快（完爆）
  + 矩阵：
      + 二维数组，矩阵的元素都是同一类型，在本实验中，m通常是行数，n是列数，矩阵的元素可以用二维索引来引用
    + Numpy 数组：
      + 在课程1中，二维矩阵用于保存训练数据，训练数据有m个示例，由n个特征创建（m,n）数组
    + 矩阵的创建：
      + a = np.zeros((1, 5)) 得到一个只一行5列的数组 ，也就是：a = [[0. 0. 0. 0. 0.]]                                      
      + a = np.zeros((2, 1))  ： a = [[0.][0.]]                                              
      + a = np.random.random_sample((1, 1)) ：a = [[0.44236513]] 
    + a = np.arange(6).reshape(-1, 2)
      + 解析：
        + 使用arrange函数创建了一个一维数组，并使用reshape方法将其重新构造为了一个特定形状的二维数组
      + 逻辑：
        + np.arrange(6) :创建了一个包含从0到5的整数的一维数组，参数6指定了数组的长度，即从0到5一共6个整数
        + .reshape(-1,2):这一部分是对先前创建的一维数组进行形状重塑的操作，reshape方法用于重新构造数组的形状。参数(-1,2) 的-1表示由系统自动计算该维度的大小，而2表示每个子数组应该包含的元素个数，由于原始数组由6个元素，reshape方法将会把这些元素重新组织为一个二维数组，其中每个子数组中由两个元素，因此结果是一个3行2列的二维数组
      + 扩展：
        + a[2,0] :获得的是二维数组a中的第三行第一列的元素
        + a[2,0].shape() :由于只是一个元素，得不到形状，所以会返回一个空元组：()
        + a[2]: 得到第三行，即一个一维数组：[4 5]
        + a[2].shape(): 由于是一个一维数组，所以可以得到形状是两行一列的元组：(2,)
        + .reshape(-1,2) 是代表函数自动，列数为2
        + .reshape(3,2) 代表3行2列
    + 矩阵的切片：
      + a[索引(索引+1=行) ，一维数组的切片 ]
      + a[0, 2:7:1] 代表获取二维数组第一行，将第一行的一维数组进行从索引2 到 索引7(不包括7) 步长为1 的切片数组
      + a[:, 2:7:1] 代表获取所有行的 切片数组，最终是一个二维数组
      + a[1, :] 获取第二行
+ Lab02：（多元线性回归）：
  + 实例被保存在Numpy矩阵 x_train中，矩阵的每一行代表一个实例，当你由m个训练实例，和n个特征时，X时一个有m行，n列的矩阵
  + 参数向量 w，b：
    + w是一个有n个元素的向量
    + b是一个参数值
  + 多元模型预测：
    + f_wb(x) = w0x0 + w1x1 + w2x2 + …… + wn-1xn-1 + b
  + 多元cost计算：
    + compute_cost 计算cost
    + 由于这一次X是一个m行n列的矩阵，所以这一次的dot product是np.dot(X[0], w)
    + 在不适用矩阵乘法的情况下，我们暂时使用for loop来实现
  + 梯度下降：
    + 计算多元的梯度：
      + compute_gradient() 计算梯度
      + 设计了一个有n行的dj_dw 一维数组，原因是x的特征值有n个
      + 梯度是一个纵向（n行1列）的矩阵，代码层面就是一个数组，n行对应n个x的特征值（n个w的值）
    + 梯度下降计算：
      + 在compute_gradient()中，我们已经计算好了梯度，它是一个有n个元素的数组
      + 此时我们有w，一个有n个w值的数组
      + 我们还有一个学习率alpha
      + w = w - alpha * dj_dw ，该式子完成梯度下降
+ lab_utils_multi:
  
  + load_data_multi():
    + 该函数用于从文件中加载多变量线性回归数据集，具体而言，它假设数据文件采用逗号分隔的格式，其中每行表示一个数据样本，包含多个特征和一个目标值，函数加载数据文件并将特征和目标值分别存储在变量X和y中，并返回它们
    + 逻辑分析：
      + 使用Numpy的loadtxt() 函数加载文件，该函数允许从文本文件中加载数据
      + 通过指定 delimiter=',' 参数来指定逗号作为数据的分隔符
      + 使用切片操作将特征和目标值分别存储在变量X和y中
      + 最后返回特征矩阵X和目标值向量y
    + 特殊点：
      + data[:, :2] ：表示对数组data进行切片操作，将选择所有行和前两列的数据，该切片操作用于获取数据集中的特征部分
      + data[:, 2] : 表示对data进行切片，选择所有行，以及第二列的数据（是从0开始）
  
  + plt_house_x():
    + 参数分析
      + X：房屋尺寸数据的数组
      + y：房屋价格数据的数组
      + f_wb：预测的房价数据，通常是一个一维数组，表示预测的房价曲线
      + ax： 用于指定绘图所在的子图
    + 内部逻辑：
      + 如果没有提供ax参数，即可以指定绘图所在的子图对象，则创建一个新的图形和子图对象，并将它们分配给fig和ax变量，这里使用了plt.subplots函数来创建一个包含子图的图形
      + ax.scatter(X,y,marker='x',c='r',label="Actual Value"):在子图ax上创建散点图
      + 设置子图标题，纵轴标签，横轴标签
      + 如果提供了预测的房价数据f_wb
      + 就在子图上绘制预测的房价曲线
      + ax.legend() 显示图例，将散点图和预测曲线的标签显示在图形中
  
  + mk_cost_lines(): 再二维空间中绘制代价函数的等高线图，它的作用是可视化代价函数的变化趋势
    + 参数分析：
      + cost_fn: 代价函数，是一个接收两个参数theta0 和 theta1 的函数，返回代价值
      + theta0_range: 截距的取值范围，通常作为一个一维数组或元组，用于绘制等高线图
      + theta1_range: 斜率的取值范围，通常作为一个一维数组或元组，用于绘制等高线图
      + X : 自变量的特征数据
      + y： 因变量的数据
      + ax(可选) ：用于指定绘图所在的子图，如果未提供，函数将创建一个新的图形和子图
    + 内部逻辑：
      + 如果没有提供ax参数，即没有指定绘图所在的子图对象，就创建一个新的图形和子图对象，并将它们分配给fig和ax变量
      + T0，T1 = np.meshgrid(theta0_range, theta1_range) : 使用np.meshgrid函数创建一个网格，其中T0对应于theta0_range,T1对应与theta1_range 这样做是为了在二维空间中绘制等高线图
      + zs = np.array([cost_fn(t0,t1,X,y) for t0,t1 in zip(np.ravel(T0),np.ravel(T1))]) : 计算每个网格点的代价值，np.ravel 用于将二维数组展平成一维数组，并使用列表推导式计算每个点的代价值
      + Z = zs.reshape(T0.shape) : 将代价值重新塑造为与网格相同的形状，以便于绘制等高线图
      + ax.contour(T0, T1, Z, np.logspace(-2,3,20), cmap=cm.plasma):在子图ax上绘制等高线，参数含义如下：
        + T0：截距的取值范围网格
        + T1： 斜率的取值范围网格
        + Z： 代价值的网格
        + np.logspace(-2,3,20) : 指定等高线的高度级别，这里使用对数尺度在10^(-2) 到 10^3 之间生成20个高度级别
        + cmap=cm.plasma: 指定等高线图的颜色映射，这里使用plasma颜色映射
      + 设置横轴标签为theta0
      + 设置纵轴标签为theta1
  + inbounds() : 用于检查两个点是否都在给定范围内
    + 参数解析：
      + a： 第一个点的坐标，是一个二元组（ax，ay），表示x和y坐标
      + b： 第二个点的坐标，也是一个二元组（bx，by）
      + xlim：x轴的范围，也是一个二元组（xlow，xhigh），表示最小值和最大值
      + ylim：y轴的范围，也是一个二元组（ylow，yhigh）
    + 函数首先将输入的点分别与x和y轴的范围进行比较，检查它们是否都在范围内，如果两个点的x坐标和y坐标都在对应的范围内，则返回True 否则返回False
  + plot_contour_wgrad() : 用于绘制等高线图的函数，同时包含了梯度信息的可视化
    + 参数解析：
      + x，y：数据集的特征和标签
      + hist：梯度下降的历史记录，即每次迭代时的权重和偏置
      + ax：绘图对象
      + w_range,b_range:权重和偏置的取值范围
      + contours:要绘制的等高线的值
      + resolution: 梯度下降路径的分辨率
      + w_final,b_final:最终的权重和偏置值
      + step:绘制梯度下降路径时的步长
    + 逻辑解析：
      + 首先使用np.meshgrid()创建了一个二维网格，其中w0表示权重的范围，b0表示偏置的范围
      + z=np.zeros_like(b0)：创建了一个和b0 一样大小的全零数组z，用于存储每个网格点对应的代价函数值
      + 遍历权重范围的每一行，遍历权重范围的每一列，计算每个网格点的代价函数值，这里调用了compute_cost() 函数，用于计算代价值
      + 使用ax.contour() 绘制等高线图，传入了权重和偏置的网格点w0，b0，代价函数值z，以及等高线的值contours
      + 在等高线上添加标签，设置x轴y轴标签，设置图形标题
      + 设置最终的权重和偏置
      + 在图中绘制水平和垂直的虚线，表示最终的权重和偏置
      + 将起始点设置为历史记录中的第一个点
      + 遍历历史记录中的每一个点，步长为step
      + 计算当前点与起始点之间的欧氏距离
      + 如果距离大于分辨率或者当前点是历史记录的最后一个和点，则进行下一步操作
      + 检查当前点是否在图形范围内
      + 在图中绘制箭头，表示梯度下降的路径，更新起始点为当前点，返回绘制的图形
  + plt_contour_multi():用于绘制包含多个参数的等高线图
    + 参数解析：
      + x，y：输入数据
      + w：权重，b：偏置
      + ax：轴对象
      + prange：包含参数范围的列表，准确来说是一个包含元组的列表，每个元组包含三个值：起始值，结束值，步长
      + p1和p2：参数的索引，prange[p1] 表示第p1个参数的取值范围，
      + title，xlabel，ylabel：图的标题和轴标签
    + 逻辑解析：
      + 定义了等高线的级别，即代价函数的值
      + 使用np.meshgrid 创建参数空间的网格px和py，然后初始化与px相同形状的数组z，用于存储代价函数值
      + 使用嵌套函数计算网格上的每个点的代价函数值，其中根据p1和p2的索引更新相应的参数值
        + 嵌套解析：
          + 通过两个嵌套遍历所有的网格点(i,j) 其中i表示行索引，j表示列索引
          + 在每个网格点处，根据当前的参数取值，计算相应的代价函数值，为此首先初始化变量w_ij，b_ij, 分别表示权重和偏置，然后根据当前的参数索引p1和p2，更新w_ij和b_ij：
            + 如果p1或p2小于或等于3（即权重的索引范围），则将对应位置的权重值更新为网格点（i，j）对应的值，即px[i,j] 或py[i,j]
            + 如果p1或p2 等于4（即偏置的索引范围），则将偏置值b_ij 更新为网格点（i，j）对应的值，即px[i,j] 或py[i,j]
          + 最后根据更新后的权重w_ij和偏置b_ij，计算相应的代价函数值，并将其存储在z[i][j] 中，这样就完成了对每个网格点处代价函数值的计算
      + 绘制等高线，并为等高线添加标签，设置x轴和y轴的标签，以及图的标题
  + plt_equal_scale():
    + 逻辑解析：
      + 创建一个包含两个子图的画布，大小为（12，5）
      + 定义参数范围列表prange，包含了五个参数范围的设定
      + 定义最佳参数w_best和b_best
      + 绘制第一个子图，未标准化数据的代价轮廓图
      + 重新定义prange，这次用于标准化数据的代价轮廓图（特征缩小）
      + 定义新的最佳参数，用于标准化数据
      + 绘制第二个子图，标准化数据的代价轮廓图
      + 设置整体标题
      + 调整子图布局，确保标题不会被裁切
  + plt_divergence(): 用于绘制损失函数在学习率过大时的发散情况
    + 逻辑分析：
      + 定义变量和数组：
        + x，y，v，分别用于存储历史迭代中的参数p_hist,J_hist中的位置和损失值
      + 创建绘制对象：
        + 创建了一个大小为（12，5）的图形对象fig，并调整了子图之间的水平间距
        + 使用add_gridspec 创建了一个网格布局，其中一行五列
      + 绘制第一个子图：
        + 在网格的第一列绘制了第一个子图，该子图显示了成本函数随参数w的变化趋势
        + fix_b被固定为100
        + 创建了一个w_array数组，表示w参数的范围
        + 使用了循环计算了每个w值下的损失值，并将结果存储在cost数组中
        + 使用了plot函数绘制了w_array和cost之间的关系曲线
        + 使用plot 函数在同一图上绘制了历史迭代中的x和v值，其中x表示w值，v表示损失值
        + 设置了子图的标题，y轴标签和x轴标签
      + 绘制第二个子图：
        + 在网格的第三到最后一列绘制了第二个子图，该子图显示了损失函数随参数w和b的变化情况的三维图像
        + 创建了tmp_b,tmp_w数组，分别表示b和w参数的范围
        + 使用循环计算了每个（w，b）值下的损失值，并将结果存储在z数组中
        + 使用plot_surface函数绘制了三维图像，其中tmp_w，tmp_b和z分别表示w，b和损失值
        + 设置了子图的标题和坐标轴标签
      + 其他设置：
        + 使用view_init方法调整了第二个子图的视角
        + 最后将绘制的图形对象返回、
    + 该函数的主要作用是可视化损失函数在参数过大的情况下的发散情况，通过两个子图分别展示了损失函数随参数w变化的趋势以及损失函数随参数w和b变化的三维图像
  + add_line : 用于在图中添加一个切线来表示损失函数的局部斜率
    + 输入参数：
      + dj_dx : 局部斜率的值
      + x1,y1 : 切线上的一个点的坐标
      + d： 控制切线长度的参数
      + ax： 要添加切线的坐标轴对象
    + 函数实现：
      + 创建一个x数组，其中包含了以x1-d 到 x1+d 为范围的50个均匀间隔的值
      + 使用线性方程y=dj_dx*(x-x1) + y1 计算了切线上各点的y值
      + 使用scatter方法在切线上的一点（x1，y1）处添加了一个散点，用于表示切线与损失函数曲线的交点
      + 使用plot 方法绘制切线，采用虚线样式，颜色为深红色，并设置了zorder属性以确保切线位于其他图形之上
      + 使用annotate 方法添加了一个带箭头的文本标签，用于显示局部斜率的值，箭头指向（x1，y1），文本的偏移量为（xoff，10），文本样式为左上方对齐
    + 这个函数的作用是在图中添加一个切线，用于表示损失函数在某一点的局部斜率
  + plt_gradients:
    + 参数解析：
      + x_train ： 训练数据的特征
      + y_train : 训练数据的目标值
      + f_compute_cost: 计算代价函数的函数
      + f_compute_gradient: 计算梯度的函数
    + 逻辑解析：
      + 创建一个包含两个子图的图形，水平排列，大小为12*4
      + 在第一个子图中绘制代价函数J 关于参数w的曲线
      + 使用f_compute_cost 函数计算代价函数的值
      + 绘制w在区间[-100,500] 内的50个等间距取值对应的代价函数值
      + 设置子图标题，y轴标题，x轴标题
      + 对于给定的几个w值（100，200，300），计算相应的梯度并在图中绘制与这些w值对应的切线
      + 使用f_compute_gradient 函数计算梯度，使用add_line 函数在图中添加切线
      + 在第二个子图中绘制参数w和b上的梯度向量场
      + 使用f_compute_gradient 函数计算参数空间中每个点的梯度
        + U和V分别代表了每个网格点处的w和b方向上的梯度分量
      + 使用quiver 函数绘制梯度向量场，并根据梯度向量的大小和方向着色
      + 设置子图的标题，x轴标签，y轴标签
  + norm_plot: 绘制数据的直方图和正态分布曲线
    + 逻辑解析：
      + 计算数据的范围，然后将其扩大20%，以便在直方图周围留出一些空间
      + 生成一个包含直方图边界值的数组，用于定义直方图的区间，这里选择了50个间隔来绘制直方图
      + 利用hist函数绘制直方图，传入数据data和区间边界值x，绘制直方图，并返回每个区间的边界值bins，由于直方图的值不被使用，所以用下划线_ 表示丢弃这个返回值
      + 计算数据均值mu和标准差std，然后利用norm.pdf 函数计算正态分布的概率密度函数，这将生成一个与直方图相对应的正态分布曲线，其中loc参数设置为均值，scale参数设置为标准差
      + 创建一个与原始坐标轴ax共享x轴的次坐标轴axr，这将使得后续的正态分布曲线可以与直方图在同一图表上进行比较
      + 利用plot函数在次坐标轴上绘制正态分布曲线，传入直方图的边界值bins和相应的概率密度函数值dist，并设置颜色为橙红色，线宽为2
      + 通过设置次坐标轴的y轴范围，确保正态分布曲线的底部与x轴对齐，这样可以更好地展示正态分布曲线与直方图之间的关系
      + 关闭次坐标轴的坐标轴显示，即不显示坐标轴刻度和标签，这样可以使图标更加清晰，减少不必要的视觉干扰
  + plot_cost_i_w: 用于绘制成本函数随着迭代次数和参数w[0] 的变化情况
    + 逻辑解析：
      + 第一部分：
        + 从历史记录中提取参数w的值，并存储在数组ws中
        + 计算参数w的范围，即最小值和最大值的绝对值中的较大值
        + 在参数w[0] 的范围内生成20个均匀分布的值，并存储在数组wr中
        + 计算每个w[0] 对应的成本函数值，并存储在数组cst中
      + 第二部分：
        + 思路：
          + 创建一个包含两个子图的画布，其中一个子图用于绘制成本函数随迭代次数的变化，另一个子图用于绘制成本函数随w[0] 的变化
        + 在第一个子图中绘制迭代次数与成本函数之间的关系
        + 设置第一个子图的标题为成本vs迭代次数
        + 设置第一个子图的x轴标签为 迭代次数
        + 设置第一个子图的y轴标签为成本
        + 在第二个子图中绘制w[0] 与成本函数之间的关系
        + 设置第二个子图的标题为 成本vs w[0]
        + 设置第二个子图的x轴标签为 w[0]
        + 设置第二个子图的y轴标签为 成本
        + 在第二个子图中绘制w[0] 随迭代次数的变化曲线
  
  
  + compute_gradient_matrix: 使用矩阵运算计算梯度
  
  + compute_cost_matrix: 计算线性回归模型的成本
  
  + compute_gradient： 计算梯度（for loop）
  
  + compute_gradient: 计算成本（for loop）
  
  + gradient_descent_houses ：执行批量梯度下降来学习线性回归模型参数的函数
    + 参数说明：
      + X：输入数据矩阵，大小为（m，n），其中m是样本数量，n为特征数量
      + y：实际值数组，大小为（m，），与输入数据对应
      + w_in：模型参数的初始值，大小为（n，），即特征的权重
      + b_in：标量，偏置项
      + cost_function: 计算成本的函数
      + gradient_function： 计算梯度的函数
      + alpha：学习率
      + num_iters: 迭代次数，即要执行梯度下降的步数
    + 返回值：
      + w：更新后的模型参数w，大小为（n，）
      + b：更新后的模型参数b，标量
      + hist：一个字典，包含每次迭代过程中的成本，参数和梯度信息，用于后续绘图
    + 计算过程：
      + 对于每次迭代：
        + 计算梯度dj_dw和dj_db，使用gradient_function函数
        + 根据梯度和学习率，更新参数w和b
        + 计算成本函数值，并将成本，参数和梯度信息保存到hist中
        + 每隔一段时间打印当前迭代的成本，参数和梯度信息
    + 最后，返回更新后的参数w和b，以及用于绘图的历史信息hist
  
  + run_gradient_descent:运行梯度下降算法来优化线性回归模型的参数
    + 参数解析：
      + X：输入数据矩阵，大小为（m，n），其中m是样本数量，n是特征数量
      + y：实际值数组，大小为（m，），与输入数据对应
      + iteration：迭代次数，即要执行梯度下降的步数，默认为1000次
      + alpha：学习率
    + 返回值：
      + w_out：通过梯度下降得到的更新后的模型参数w，大小为（n，）
      + b_out：通过梯度下降得到的更新后的参数模型b，标量
      + hist_out：一个字典，包含在每次迭代过程中的成本，参数和梯度信息，用于后续绘制图
    + 计算过程：
      + 初始化参数 initial_w和initial_b
      + 调用gradient_descent_houses 函数来执行梯度下降优化过程
      + 输出梯度下降过程中得到的最终模型参数w_out 和b_out
    + 最后，函数返回优化后的模型参数以及梯度下降过程的历史信息hist_out
  
  + run_gradient_descent_feng: 运行梯度下降算法来优化线性回归模型的参数，只返回优化后的模型参数（w_out，b_out）
  
  + load_house_data ：用于加载房屋数据集
    + 逻辑解析：
      + 从名为 houses.txt的文件中，加载数据，并将数据存储在data变量中
      + 从加载的数据中提取特征矩阵X，data是一个二维数组，其中每一行代表一个和样本，而每一列代表一个特征，该行代码将前四列的数据提取出来，作为特征矩阵X
      + y=data[:,4] 将第五列的数据提取出来，作为目标向量y
  
  + zscore_normalize_features:
    + 目的：
      + 执行Z分数标准化，按列对输入矩阵X进行标准化，即对每列的数据进行标准化，是均值为0，标准差为1
    + 参数说明：
      + X：输入的numpy数组，大小为（m，n）
      + rtn_ms:一个布尔值，用于指示是否返回均值和标准差
    + 返回值说明：
      + X_norm: Z分数标准化后的特征矩阵，与输入矩阵具有相同的大小
      + 如果rtn_ms为True，则还会返回均值mu和标准差sigma
    + 内部逻辑：
      + 计算输入矩阵X每列的均值mu，这是一个大小为n的向量，其中n表示为特证数
      + 计算输入矩阵X每列的标准差sigma，也是一个大小为n的向量
      + 使用公式进行Z分数标准化
      + 如果rtn_ms为True，则返回Z分数标准化后的特征矩阵X_norm，均值mu和标准差sigma，否则仅返回X_norm 


+ public_tests :
  
  + compute_cost_test: 测试用函数，用于测试成本函数计算
    + 逻辑解析：
      + 接受一个参数target，该参数是一个函数
      + 创建一个Numpy数组x，包含了四个元素2，4，6，8  然后将其转置
      + 创建一个Numpy数组y，包含了四个元素，并将其转置
      + 初始化参数 initial_w为2
      + 初始化参数 initial_b为3.0
      + 调用传入的target函数，并传入参数，得到成本值，并将其赋值给cost
      + 使用断言语句检查 cost 是否等于0，如果不等于则输出错误信息，这是一个单元测试的关键，用于确保函数的输出符合预期
        + assert:关键字，用于断言某个条件是否为真，如果为真，程序就继续执行，如果为假，程序就抛出AssertionError异常，并停止执行
        + cost==0：是要断言的条件，在这个情况下，我们希望cost的值等于0
        + ‘，’ ：逗号用于分隔断言条件和断言失败时的错误信息
        + f"" 这是断言失败要输出的错误信息
      + 后续代码块依次类似，测试不同情况下函数的行为和输出是否符合预期，每个测试用例都会调用target函数并检查输出的成本值
      + 最后一行，如果所有的测试用例通过了断言语句的检查，就会打印出：\033[92mAll tests passed!，表示所有测试用例都通过了，\033[92m 是ANSI转义码，用于给终端输出添加颜色（绿色）
  + compute_gradient_test: 测试用函数，用于测试梯度计算：
    + 逻辑解析：
      + 接受一个参数target，该参数是一个函数
      + 指示将使用形状为（4，1）的输入数据进行测试
      + 创建一个形状为（4，1）的Numpy数组x，包含四个元素，并将其转置（这里没有实际意义，因为x是一维的）
      + 创建一个形状为（4，1）的Numpy数组y，包含四个元素，并将其转置
      + 初始化参数 initial_w
      + 初始化参数 initial_b
      + 调用传入的target函数，并传入参数，得到权重梯度dj_dw和偏置梯度dj_db
      + 使用断言语句检查偏置梯度
      + 使用断言语句检查权重梯度
